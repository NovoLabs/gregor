# Gregor

[![PyPI](https://img.shields.io/pypi/l/Django.svg?style=plastic)]()
[![CircleCI](https://circleci.com/gh/NovoLabs/gregor/tree/master.svg?style=svg)](https://circleci.com/gh/NovoLabs/gregor/tree/master)


> As Gregor Samsa awoke one morning from uneasy dreams he found himself transformed in his bed into a gigantic insect.

― Franz Kafka, _The Metamorphosis_

## Description

Gregor provides a channel-based API for asynchronously producing and consuming messages from a Kafka instance.  Through the use of transducers, Gregor allows the user to transform data on either the production or consumption side, or both if necessary.

Gregor provides a control channel for interacting with the producer and consumer APIs.  Though it is not a complete implementation of the current Kafka producer and consumer objects, the operation set supports most use cases.  Additional control operations will be implemented as necessary.

## Inspirations

Gregor was inspired by [kinsky](https://github.com/pyr/kinsky) and [ring](https://github.com/ring-clojure).

## Dependencies

Since Gregor is an interface to Kafka, using it requires a Kafka instance.  To help you get up and running quickly, Gregor provides a `docker-compose.yaml` file that can be used to start up a local instance of Kafka.  Assuming you have [`docker-compose`](https://docs.docker.com/compose/install/) installed, you can copy [Gregor's docker compose file](https://github.com/NovoLabs/gregor/blob/master/docker/docker-compose.yaml) from GitHub to your local machine.

Once you copy Gregor's `docker-compose.yaml` file to your local machine (and `docker-compose` is installed), you can start Kafka with the following command:

```shell
$ docker-compose up
```

## Installation

To install Gregor, add the following to your Leiningen `:dependencies` vector:

```clojure
[codes.novolabs/gregor "0.1.0"]
```

## Usage

Gregor provides 2 interfaces: One for producing messages and the other for consuming them.

### Creating a consumer

To create a consumer, we first need to pull the consumer namespace into our REPL:

```clojure
(require '[gregor.consumer :as c])
```

Assuming we have Kafka running on port 9092 on our local machine (the default location if we used the `docker-compose.yaml` file provided by Gregor), we can create a consumer connection using the following code:

```clojure
user> (def consumer (c/create {:output-policy #{:data :control :error}
                               :topics :gregor.test
                               :kafka-configuration {:bootstrap.servers "localhost:9092"
                                                     :group.id "gregor.consumer.test"}}))
;; => #'user/consumer
```

Lets take a closer look at the configuration map passed to `gregor.consumer/create`:

**`:output-policy`**

The value of `:output-policy` should be a set containing the types of events we want published to `out-ch`.  There are four types of events that Gregor supports:

* `:data` - Data events are generated by messages read from the configured topic or topics.  This event type is always included in a consumer's `:output-policy`, regardless of what is specified in the user-supplied `:output-policy`.  Without data events, the consumer would not be very useful.
* `:control` - Control events are generated by the output of control operations sent to the control channel.  We will talk more about the control channel and the supported operations below.
* `:error` - Error events are generated when errors occur, most commonly when an exception is thrown or invalid control operations are passed to the control channel.
* `:eof` - EOF events are sent when an output channel is closed (exclusively from invoking the `:close` control operation).  Like `:data` events, the `:eof` event is always included as part of the `:output-policy` as Gregor strives to be a good citizen and indicate to the user when the stream of events has completed.

**`:topics`**

The value of `:topics` can be a string, a keyword, a vector of strings and keywords or a regular expression:

* A string or keyword will subscribe the consumer to a single topic.  The string or keyword should be a [valid Kafka topic](https://stackoverflow.com/questions/37062904/what-are-apache-kafka-topic-name-limitations).
* A vector of strings and keywords will subscribe the consumer to each topic in the vector.  The vector can contain both strings and keywords.
* A regular expression will subscribe the consumer to all topics matching the regular expression.

You can check out the [KafkaConsumer documentation](https://kafka.apache.org/21/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html) for more information.

**`:kafka-configuration`**

The value of `:kafka-configuration` should be a map containing Kafka configuration options.  This map will be converted to a Java properties map and passed directly to the KafkaConsumer object during initialization.  The minimum requirements for consumer initialization are:

* `:bootstrap.servers` - A comma-delimited string containing `host:port` pairs inidicating the location of the Kafka server.
* `:group.id` - A string containing the group id of the consumer, which is used to maintain indexes and handle partitioning

You can check out the [Kafka documentation](https://kafka.apache.org/documentation/#configuration) for full treatment of all of the available configuration options.

### Consumer Control Operations

Assuming correct configuration, the result of calling `gregor.consumer/create` is a map containing 2 keys:

* `:out-ch` - The channel that receives all events, including `:data`, `:control` and `:error`.
* `:ctl-ch` - The channel that is used to send control operations

For the sake conveneince, lets bind `out-ch` to the output channel and `ctl-ch` to the control channel:

```clojure
user> (def out-ch (:out-ch consumer))
;; => #'user/out-ch

user> (def ctl-ch (:ctl-ch consumer)) 
;; => #'user/ctl-ch
```

Now, lets check if we have been properly subscribed to the `gregor.test` topic.  We can query for the list of current subscriptions using the `:subscriptions` control operation.  The output will be written to `out-ch` as a `:control` event.  Here is the code:

```clojure
user> (require '[clojure.core.async :as a])

user> (a/>!! ctl-ch {:op :subscriptions})
;; => true

user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :subscriptions, :subscriptions ["gregor.test"], :event :control}
```

This is a common pattern in Gregor:  The operation is submitted to the control channel and any results are pushed to the output channel as a `:control` event.

Now lets have a look at the control operations that the consumer supports:

**`:subscribe`**

The `:subscribe` operation is used to subscribe to a topic(s).  Since Gregor requires that the initial topic(s) be passed in during initialization, the `:subscribe` operation will generally only be used if we wish to change the subscription of our consumer.  Should you need to do this, please remember that per the [KafkaConsumer documentation](https://kafka.apache.org/21/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html), **topic subscriptions are not incremental**.  If you wish to remain subscribed to the current list of topics, you will need to include these along with any additions when you call the `:subscribe` operation.

The code to call `:subscribe` looks like this:

```clojure
;; Subscribe to `:gregor.test.2`
user> (a/>!! ctl-ch {:op :subscribe :topics :gregor.test.2})
;; => true

;; Print the output from the `:subscribe` control operation
user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :subscribe, :topics :gregor.test.2, :event :control}

;; Query for the list of current subscriptions using the `:subscriptions` operation
user> (a/>!! ctl-ch {:op :subscriptions})
;; => true

;; Print the output of the `:subscriptions` operation, noting that we are
;; now subscribed to the "gregor.test.2" topic
user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :subscriptions, :subscriptions ["gregor.test.2"], :event :control}

;; Switch subscription back to "gregor.test"
user> (a/>!! ctl-ch {:op :subscribe :topics :gregor.test})
;; => true

;; Print the output of the `:subscribe` command
user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :subscribe, :topics :gregor.test, :event :control}
```

**`:subscriptions`**

The `:subscriptions` operation, as we have seen, is used to get the list of topics that the consumer is currently subscribed to.  We have already seen how to call the `:subscriptions` operation above but we include the code here for the sake of completness:

```clojure
;; Query for the list of current subscriptions using the `:subscriptions` operation
user> (a/>!! ctl-ch {:op :subscriptions})
;; => true

;; Print the output of the `:subscriptions` operation
user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :subscriptions, :subscriptions ["gregor.test"], :event :control}
```

If the consumer is not subscribed to a topic(s), the `:subscriptions` operation will return an empty vector

**`:unsubscribe`**

The `:unsubscribe` operation will unsubscribe the consumer from all current topic subscriptions.  It can be invoked using the following code:

```clojure
;; Unsubscribe from the current topic
user> (a/>!! ctl-ch {:op :unsubscribe})
;; => true

;; Print the output of the `:unsubscribe` operation
user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :unsubscribe, :event :control}
```

If you are switching betwen a name-based subscription (i.e. strings or keywords) to a pattern-based subscription (i.e. a regular expression), you must unsubscribe.  If you want to change from one name-based subscription to another or one pattern-based subscription to another, you do not need to unsubscribe.

**`partitions-for`**

The `:partitions-for` operation will fetch the partition information for the specified topic.  You can use the following code to test `:partitions-for` for the `"gregor.test"` topic:

```clojure
;; Query the partitions for the `:gregor.test` topic
user> (a/>!! ctl-ch {:op :partitions-for :topic :gregor.test})
;; => true

;; Print the output of the `:partitions-for` operation for the `:gregor.test` topic
user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :partitions-for, 
;;     :topic :gregor.test, 
;;     :partitions [{:type-name :partition-info, 
;;                   :isr [{:type-name :node, :host "127.0.0.1", :id 1, :port 9092}], 
;;                   :offline [], 
;;                   :leader {:type-name :node, :host "127.0.0.1", :id 1, :port 9092}, 
;;                   :partition 0, 
;;                   :replicas [{:type-name :node, :host "127.0.0.1", :id 1, :port 9092}], 
;;                   :topic "gregor.test"}], 
;;     :event :control}
```

**`commit`**

The `:commit` operation will commit the offsets from the last call to poll for the subscribed list of topics.  The default value of the `enable.auto.commit` property in Kafka is `true`, which means that as messages are consumed, the offset will be committed automatically (the interval of auto commits is controlled by the `auto.commit.interval.ms` property which has a default value of `500`).  If you set `enable.auto.commit` to `false` when you create your consumer you will need to manually commit consumed offsets, which can be done with the following code:

```clojure
;; Commit the last consumed offset for this consumer
user> (a/>!! ctl-ch {:op :commit})
;; => true

;; Verify that the `:commit` operation was processed succesfully
user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :commit, :event :control}
```

Leaving `enable.auto.commit` set to the default value of `true` is sufficient for most use cases.  Read [this Medium article](https://medium.com/@danieljameskay/understanding-the-enable-auto-commit-kafka-consumer-property-12fa0ade7b65) for more information about auto committing and offsets.

**`:close`**

The `:close` operation will close the consumer, including all associated channels.  The following code will close the consumer we have been working with:

```clojure
;; Close the consumer
user> (a/>!! ctl-ch {:op :close})
;; true

;; Verify the `:close` operation was processed
user> (-> (a/<!! out-ch) pr-str println)
;; => {:op :close, :event :control}

;; Should receive `:eof` event as the final event indicating the end of the stream/channel
user> (-> (a/<!! out-ch) pr-str println)
;; => {:event :eof}

;; Further reads result in `nil` as the `out-ch` is closed
user> (-> (a/<!! out-ch) pr-str println)
;; => nil

;; Attempts to write to the `ctl-ch` will fail, returning `false`
(a/>!! ctl-ch {:op :subscriptions})
;; => false
```

Not only was the KafakConsumer object closed, but so were the `out-ch` and `ctl-ch` channels.  Since `out-ch` is a standard `core.async` channel, all messages that were read from the consumer up to the point of the `:close` operation will be avialable.  Once `out-ch` is empty, it wil return `nil` for all future reads.  Any attempts to write to the `ctl-ch` will fail, returning `false` as shown above.

Note that the final message deliverd from the `out-ch` was the `:eof` event.  Posting an `:eof` event is Gregor's way of telling the user that the stream has been closed.

## License

Copyright © 2019 NovoLabs, Inc.

Distributed under the BSD-3-clause LICENSE
